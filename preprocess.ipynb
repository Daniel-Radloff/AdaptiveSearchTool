{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "names = [\"duration\",\"protocoltype\",\"service\",\"flag\",\"srcbytes\",\"dstbytes\",\"land\", \"wrongfragment\",\"urgent\",\"hot\",\"numfailedlogins\",\"loggedin\", \"numcompromised\",\"rootshell\",\"suattempted\",\"numroot\",\"numfilecreations\", \"numshells\",\"numaccessfiles\",\"numoutboundcmds\",\"ishostlogin\",\n",
    "\"isguestlogin\",\"count\",\"srvcount\",\"serrorrate\", \"srvserrorrate\",\"rerrorrate\",\"srvrerrorrate\",\"samesrvrate\", \"diffsrvrate\", \"srvdiffhostrate\",\"dsthostcount\",\"dsthostsrvcount\",\"dsthostsamesrvrate\", \"dsthostdiffsrvrate\",\"dsthostsamesrcportrate\",\n",
    "\"dsthostsrvdiffhostrate\",\"dsthostserrorrate\",\"dsthostsrvserrorrate\",\"dsthostrerrorrate\",\"dsthostsrvrerrorrate\",\"attack\", \"lastflag\"]\n",
    "# Read in the data into a dataframe\n",
    "df = pd.read_csv(\"Data/Train.txt\",sep=\",\",names=names)\n",
    "\n",
    "\n",
    "# df.head()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that there are no missing values\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are only interested in normal and attack categories so map all attacks to 1 and normal to 0\n",
    "\n",
    "df['attack'] = df['attack'].map(lambda x: 0 if x == 'normal' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want all attributes to be numeric, so check what attributes is not numeric\n",
    "\n",
    "non_numeric_columns = df.select_dtypes(exclude=[int, float, bool]).columns\n",
    "\n",
    "print(\"Non numeric columns\", non_numeric_columns)\n",
    "\n",
    "# We can see that protocoltype, service and flag are not numeric. We will convert these to numeric using LabelEncoder\n",
    "protocol_map = {\n",
    "        'icmp': 0,\n",
    "        'tcp': 1,\n",
    "        'udp': 2\n",
    "}\n",
    "    \n",
    "service_map = {\n",
    "    'IRC': 0, 'X11': 1, 'Z39_50': 2, 'aol': 3, 'auth': 4, 'bgp': 5, 'courier': 6, 'csnet_ns': 7,\n",
    "    'ctf': 8, 'daytime': 9, 'discard': 10, 'domain': 11, 'domain_u': 12, 'echo': 13, 'eco_i': 14,\n",
    "    'ecr_i': 15, 'efs': 16, 'exec': 17, 'finger': 18, 'ftp': 19, 'ftp_data': 20, 'gopher': 21,\n",
    "    'harvest': 22, 'hostnames': 23, 'http': 24, 'http_2784': 25, 'http_443': 26, 'http_8001': 27,\n",
    "    'imap4': 28, 'iso_tsap': 29, 'klogin': 30, 'kshell': 31, 'ldap': 32, 'link': 33, 'login': 34,\n",
    "    'mtp': 35, 'name': 36, 'netbios_dgm': 37, 'netbios_ns': 38, 'netbios_ssn': 39, 'netstat': 40,\n",
    "    'nnsp': 41, 'nntp': 42, 'ntp_u': 43, 'other': 44, 'pm_dump': 45, 'pop_2': 46, 'pop_3': 47,\n",
    "    'printer': 48, 'private': 49, 'red_i': 50, 'remote_job': 51, 'rje': 52, 'shell': 53, 'smtp': 54,\n",
    "    'sql_net': 55, 'ssh': 56, 'sunrpc': 57, 'supdup': 58, 'systat': 59, 'telnet': 60, 'tftp_u': 61,\n",
    "    'tim_i': 62, 'time': 63, 'urh_i': 64, 'urp_i': 65, 'uucp': 66, 'uucp_path': 67, 'vmnet': 68,\n",
    "    'whois': 69\n",
    "}\n",
    "    \n",
    "flag_map = {\n",
    "    'OTH': 0, 'REJ': 1, 'RSTO': 2, 'RSTOS0': 3, 'RSTR': 4, 'S0': 5, 'S1': 6, 'S2': 7, 'S3': 8,\n",
    "    'SF': 9, 'SH': 10\n",
    "}\n",
    "\n",
    "def map_func(x):\n",
    "    if x in protocol_map:\n",
    "        return protocol_map[x]\n",
    "    elif x in service_map:\n",
    "        return service_map[x]\n",
    "    elif x in flag_map:\n",
    "        return flag_map[x]\n",
    "\n",
    "df['protocoltype'] = df['protocoltype'].map(map_func)\n",
    "df['service'] = df['service'].map(map_func)\n",
    "df['flag'] = df['flag'].map(map_func)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop([\"numoutboundcmds\"], axis=1)\n",
    "plt.figure(figsize=(25, 15))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "# sns.heatmap(correlation_matrix)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the correlation heatmap we can see that there are some attributes that are highly correlated. We will remove these attributes as they do not add any value to the model.\n",
    "\n",
    "df = df.drop([\"dstbytes\", \"urgent\", \"hot\", \"srcbytes\", \"land\", \"numfailedlogins\", \"numroot\", \"rootshell\", \"numcompromised\", \"numoutboundcmds\" ], axis=1)\n",
    "\n",
    "plt.figure(figsize=(25, 15))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "# sns.heatmap(correlation_matrix)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=df.drop(['attack'],axis=1)\n",
    "# y=df['attack']\n",
    "\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X)\n",
    "# X_transformed = scaler.transform(X)\n",
    "\n",
    "# # df = pd.concat([pd.DataFrame(X_transformed), y], axis=1)\n",
    "\n",
    "# lr=LogisticRegression() # creates an instance of the Logistic Regression model. \n",
    "# lr.fit(X_transformed,y) #  trains the Logistic Regression model on the training data. X_transformed represents the feature matrix (input variables), and y represents the target variable (labels or classes).\n",
    "# lr_pred=lr.predict(X_transformed) # generates predictions for the training set based on the trained Logistic Regression model.\n",
    "\n",
    "# lr_df=pd.DataFrame()\n",
    "# lr_df['actual']=y\n",
    "# lr_df['pred']=lr_pred\n",
    "\n",
    "# print(accuracy_score(y, lr_pred))\n",
    "\n",
    "\n",
    "dataset_1 = df[df['attack'] == 1]\n",
    "dataset_0 = df[df['attack'] == 0]\n",
    "\n",
    "df = pd.concat([dataset_1.sample(frac=1, random_state=26), dataset_0.sample(frac=0.9, random_state=26)])\n",
    "\n",
    "\n",
    "print(df['attack'].value_counts())\n",
    "\n",
    "df.to_csv(\"Data/Train_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
